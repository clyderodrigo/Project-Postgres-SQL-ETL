{"cells":[{"cell_type":"markdown","metadata":{"id":"5WSNCN9sGlgO"},"source":["##ETL processes\n","This notebook develops the ETL process for each table before proceeding to complete the `etl.py` file to load the datasets."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":733,"status":"ok","timestamp":1680848517310,"user":{"displayName":"Clyde Rodrigo","userId":"02919227852546374690"},"user_tz":-330},"id":"nsoa0pbZWAZg","outputId":"459f23ad-87cb-4044-b398-7c96cec09754"},"outputs":[{"name":"stdout","output_type":"stream","text":["ETL-processes.ipynb  Review-dataset.ipynb    data\n","README.md\t     Star-schema-ERD.drawio  sql_queries.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting psycopg2-binary\n","  Downloading psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: psycopg2-binary\n","Successfully installed psycopg2-binary-2.9.6\n"]}],"source":["!pip install psycopg2-binary"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"elapsed":548,"status":"error","timestamp":1680848532841,"user":{"displayName":"Clyde Rodrigo","userId":"02919227852546374690"},"user_tz":-330},"id":"5IVEgF-eHV1g","outputId":"2b9539ac-7674-4ebf-ec21-d817a909526d"},"outputs":[],"source":["import os\n","import glob\n","import psycopg2\n","import pandas as pd\n","from sql_queries import *"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GN8QV57UH3P6"},"outputs":[],"source":["conn = psycopg2.connect(host=\"rosie.db.elephantsql.com\", database=\"koxdgtnq\", user=\"koxdgtnq\", password=\"hyik6zNrT28enwS3KAMIhRtCMlG4J2Ez\")\n","cur = conn.cursor()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3Lh94n3FID6m"},"outputs":[],"source":["def get_files(filepath):\n","    all_files = []\n","    for root, dirs, files in os.walk(filepath):\n","        files = glob.glob(os.path.join(root,'*.json'))\n","        for f in files :\n","            all_files.append(os.path.abspath(f))\n","    \n","    return all_files"]},{"cell_type":"markdown","metadata":{"editable":true,"id":"GU_KispREy4X"},"source":["# Process `song_data`\n","In this first part, you'll perform ETL on the first dataset, `song_data`, to create the `songs` and `artists` dimensional tables.\n","\n","Let's perform ETL on a single song file and load a single record into each table to start.\n","- Use the `get_files` function provided above to get a list of all song JSON files in `data/song_data`\n","- Select the first song in this list\n","- Read the song file and view the data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GV3ngYPSI1w9"},"outputs":[],"source":["song_files = get_files('data/song_data/')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"gbprdAHaJG2N"},"outputs":[],"source":["filepath = song_files[0]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"EYoO9PYtQ-N-"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>num_songs</th>\n","      <th>artist_id</th>\n","      <th>artist_latitude</th>\n","      <th>artist_longitude</th>\n","      <th>artist_location</th>\n","      <th>artist_name</th>\n","      <th>song_id</th>\n","      <th>title</th>\n","      <th>duration</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>ARBEBBY1187B9B43DB</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Gainesville, FL</td>\n","      <td>Tom Petty</td>\n","      <td>SOFFKZS12AB017F194</td>\n","      <td>A Higher Place (Album Version)</td>\n","      <td>236.17261</td>\n","      <td>1994</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   num_songs           artist_id  artist_latitude  artist_longitude  \\\n","0          1  ARBEBBY1187B9B43DB              NaN               NaN   \n","\n","   artist_location artist_name             song_id  \\\n","0  Gainesville, FL   Tom Petty  SOFFKZS12AB017F194   \n","\n","                            title   duration  year  \n","0  A Higher Place (Album Version)  236.17261  1994  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_json(filepath, lines=True)\n","df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["1: songs Table\n","Extract Data for Songs Table\n","Select columns for song ID, title, artist ID, year, and duration\n","Use df.values to select just the values from the dataframe\n","Index to select the first (only) record in the dataframe\n","Convert the array to a list and set it to song_data"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["['A Higher Place (Album Version)', 236.17261, 1, 1994, 'Tom Petty']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["artist_id, artist_latitude, artist_location, artist_longitude, artist_name, duration, num_songs, song_id, title, year = df.values[0]\n","song_data = song_data = [song_id, title, artist_id, year, duration]\n","song_data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Insert Record into Song Table\n","Implement the song_table_insert query in sql_queries.py and run the cell below to insert a record for this song into the songs table. Remember to run create_tables.py before running the cell below to ensure you've created/resetted the songs table in the sparkify database."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'song_table_insert' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cur\u001b[39m.\u001b[39mexecute(song_table_insert, song_data)\n\u001b[1;32m      2\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n","\u001b[0;31mNameError\u001b[0m: name 'song_table_insert' is not defined"]}],"source":["cur.execute(song_table_insert, song_data)\n","conn.commit()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMYz5Jbp6tA9gTTymkwNrzS","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
